{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMM47axrr8OV0g5VFhLLzDG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahjabeenqamar1/NLP/blob/main/NLP_Predict_Similar_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets Build a simple NLP Model that Predict Similar Words from Dataset you provide\n"
      ],
      "metadata": {
        "id": "SK4Y7IT7_E5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "jh378By--RpD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Machine_learning')\n",
        "article = scrapped_data .read()\n",
        "\n",
        "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
        "\n",
        "paragraphs = parsed_article.find_all('p')\n",
        "\n",
        "article_text = \"\"\n",
        "\n",
        "for p in paragraphs:\n",
        "    article_text += p.text"
      ],
      "metadata": {
        "id": "OhY1wo-M-Udj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reomve Stop Words¶\n"
      ],
      "metadata": {
        "id": "df2xvpEN_MBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import string\n",
        "    from nltk.corpus import stopwords\n",
        "    import nltk\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "\n",
        "class PreProcessText(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __remove_punctuation(self, text):\n",
        "        \"\"\"\n",
        "        Takes a String\n",
        "        return : Return a String\n",
        "        \"\"\"\n",
        "        message = []\n",
        "        for x in text:\n",
        "            if x in string.punctuation:\n",
        "                pass\n",
        "            else:\n",
        "                message.append(x)\n",
        "        message = ''.join(message)\n",
        "\n",
        "        return message\n",
        "\n",
        "    def __remove_stopwords(self, text):\n",
        "        \"\"\"\n",
        "        Takes a String\n",
        "        return List\n",
        "        \"\"\"\n",
        "        words= []\n",
        "        for x in text.split():\n",
        "\n",
        "            if x.lower() in stopwords.words('english'):\n",
        "                pass\n",
        "            else:\n",
        "                words.append(x)\n",
        "        return words\n",
        "\n",
        "\n",
        "    def token_words(self,text=''):\n",
        "        \"\"\"\n",
        "        Takes String\n",
        "        Return Token also called  list of words that is used to\n",
        "        Train the Model\n",
        "        \"\"\"\n",
        "        message = self.__remove_punctuation(text)\n",
        "        words = self.__remove_stopwords(message)\n",
        "        return words"
      ],
      "metadata": {
        "id": "_gv48CIm-dov"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "flag = nltk.download(\"stopwords\")\n",
        "\n",
        "if (flag == \"False\" or flag == False):\n",
        "    print(\"Failed to Download Stop Words\")\n",
        "else:\n",
        "    print(\"Downloaded Stop words ...... \")\n",
        "    helper = PreProcessText()\n",
        "    #words = helper.token_words(text=txt)\n",
        "    words = helper.token_words(text=article_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx-Vkd1K-f5z",
        "outputId": "17cbc4b2-2b96-4b4b-8124-7632fa4e7352"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Stop words ...... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model¶\n"
      ],
      "metadata": {
        "id": "AA5EV1Cd_URj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "#model = Word2Vec([words], min_count=1)\n",
        "model = Word2Vec([words], size=100, window=5, min_count=1, workers=4)\n",
        "vocabulary = model.wv.vocab\n",
        "sim_words = model.wv.most_similar('machine')\n",
        "sim_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCEjp3zY-i1Y",
        "outputId": "20f11306-1c1e-4f5a-f889-940019bc884e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('application', 0.32541361451148987),\n",
              " ('amount', 0.3222026228904724),\n",
              " ('Duda', 0.3063836097717285),\n",
              " ('become', 0.3035131096839905),\n",
              " ('hold', 0.3000921308994293),\n",
              " ('way', 0.29482632875442505),\n",
              " ('higherdimensional', 0.29479068517684937),\n",
              " ('subsets', 0.2940083146095276),\n",
              " ('outputs', 0.28732800483703613),\n",
              " ('combine', 0.2857312560081482)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = model[model.wv.vocab]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy1slnQ7-xvP",
        "outputId": "ad151d97-6e33-4554-be77-f2493286dd30"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00174176,  0.00013583,  0.00311444, ..., -0.00190061,\n",
              "         0.00077105, -0.00093764],\n",
              "       [ 0.0007755 , -0.0015892 , -0.00440444, ...,  0.00277574,\n",
              "        -0.00629605,  0.00166983],\n",
              "       [ 0.00466672,  0.00255249, -0.00168753, ..., -0.0026978 ,\n",
              "        -0.0008977 ,  0.00060971],\n",
              "       ...,\n",
              "       [-0.00276176,  0.003337  ,  0.00275615, ...,  0.00116879,\n",
              "        -0.00475915, -0.00274471],\n",
              "       [ 0.00467607,  0.00125645, -0.00329175, ...,  0.00074158,\n",
              "        -0.00278017,  0.00153217],\n",
              "       [ 0.00177848, -0.00204862, -0.00100303, ...,  0.00312646,\n",
              "         0.00234541, -0.00120253]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tZHClq1C-2PU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}